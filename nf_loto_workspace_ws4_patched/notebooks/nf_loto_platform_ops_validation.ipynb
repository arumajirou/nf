{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# nf_loto_platform 運用確認ノートブック\n（ops / 検証 / ログ・生成物チェック用）\n\nこのノートブックは、`nf_loto_platform` 一式がローカル環境で正しく動作しているかを、\n**運用視点・機能視点・テストケース視点・生成物／ログ視点**から段階的に確認するためのものです。\n\n## このノートブックでできること\n\n- DB 接続／メタデータテーブルの存在確認・初期化\n- 特徴量生成パイプラインのスモークテスト\n- AutoML / モデル実行バックエンドの最小実行\n- ログ・メトリクス・HTML レポートなどの生成物確認\n- pytest を使った回帰テストの一部実行\n\n**重要:**  \nこのノートブックは *設計上* すべてのセルを順番に実行できるようにしてありますが、\n実際の DB 接続先や GPU/ライブラリなどの環境依存があるため、\n必要に応じてセルをスキップ・編集しながら使ってください。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. 環境セットアップ\n\nまず、プロジェクトルートと `src` を Python パスに通し、バージョン情報を確認します。"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\nimport sys\nimport os\n\n# プロジェクトルート（このノートブックが置かれている notebooks/ の 1 つ上）\nNOTEBOOK_PATH = Path.cwd()\nPROJECT_ROOT = NOTEBOOK_PATH.parent\nSRC_ROOT = PROJECT_ROOT / \"src\"\n\nprint(\"NOTEBOOK_PATH:\", NOTEBOOK_PATH)\nprint(\"PROJECT_ROOT :\", PROJECT_ROOT)\nprint(\"SRC_ROOT     :\", SRC_ROOT)\n\nif str(SRC_ROOT) not in sys.path:\n    sys.path.insert(0, str(SRC_ROOT))\n    print(\"=> sys.path に SRC_ROOT を追加しました\")\n\n# バージョン情報など（必要に応じて追加）\nimport platform\nprint(\"Python :\", sys.version)\nprint(\"Platform:\", platform.platform())\n\ntry:\n    import nf_loto_platform\n    print(\"nf_loto_platform version: package import OK\")\nexcept Exception as e:  # noqa: BLE001\n    print(\"nf_loto_platform import error:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## A. DB・テーブルの確認／初期化／セットアップ\n\nこのセクションでは、以下を順番に行います。\n\n1. DB 設定ファイル（`config/db.yaml` or `db.yaml.template`）の確認\n2. `nf_loto_platform.db.postgres_manager` を使った接続テスト\n3. `sql/001_create_nf_model_run_tables.sql` などの DDL の確認\n4. 必要に応じて `setup_postgres` を使ったテーブル初期化\n\n実際の接続情報は、あなたのローカル環境の設定に合わせて編集してください。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### A-1. DB 設定ファイルの読み込みと確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.core import settings\n\ndb_cfg = settings.load_db_config()\nprint(\"DB 設定:\", db_cfg)\n\nif not db_cfg:\n    print(\"\"\"[注意] config/db.yaml または db.yaml.template から有効な設定が読み込めていません。\n      このノートブックを進める前に、DB 設定を更新してください。\n\"\"\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### A-2. PostgreSQL 接続テスト"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.db import postgres_manager\n\nconn = None\ntry:\n    conn = postgres_manager.get_connection()\n    print(\"接続成功:\", conn)\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT version();\")\n        ver = cur.fetchone()\n        print(\"PostgreSQL version:\", ver)\nexcept Exception as e:  # noqa: BLE001\n    print(\"[接続エラー] DB に接続できませんでした:\", e)\nfinally:\n    if conn is not None:\n        conn.close()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### A-3. nf_* メタデータテーブルの存在確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.db_metadata import schema_definitions\n\nNF_TABLES = [\n    schema_definitions.NF_MODEL_RUNS_TABLE,\n    schema_definitions.NF_MODEL_REGISTRY_TABLE,\n    schema_definitions.NF_FEATURE_SETS_TABLE,\n    schema_definitions.NF_DATASETS_TABLE,\n    schema_definitions.NF_DRIFT_METRICS_TABLE,\n    schema_definitions.NF_RESIDUAL_ANOMALIES_TABLE,\n    schema_definitions.NF_REPORTS_TABLE,\n]\n\nprint(\"チェック対象テーブル:\", NF_TABLES)\n\ndef list_tables():\n    from nf_loto_platform.db import postgres_manager\n    with postgres_manager.get_connection() as conn:\n        with conn.cursor() as cur:\n            cur.execute(\"\"\"\n                SELECT tablename\n                FROM pg_catalog.pg_tables\n                WHERE schemaname NOT IN ('pg_catalog', 'information_schema')\n                ORDER BY tablename;\n            \"\"\")\n            return [r[0] for r in cur.fetchall()]\n\ntry:\n    existing = list_tables()\n    print(\"既存テーブル一覧:\", existing)\n    missing = [t for t in NF_TABLES if t not in existing]\n    if missing:\n        print(\"[注意] 足りないテーブル:\", missing)\n    else:\n        print(\"すべてのメタデータテーブルが存在します。\")\nexcept Exception as e:  # noqa: BLE001\n    print(\"[エラー] テーブル一覧取得に失敗:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### A-4. DDL の実行によるメタデータテーブル初期化\n\n必要であれば、`nf_loto_platform.db.setup_postgres` を経由して\n`sql/001_create_nf_model_run_tables.sql` などの DDL を実行し、メタデータテーブルを作成します。\n\n> ⚠ **注意:** 本番環境で実行する場合は、必ず事前にバックアップを取得してから実行してください。"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.db import setup_postgres\n\n# 実行前に本当に良いかどうかのフラグ\nEXECUTE_DDL = False  # True にすると DDL を実行\n\nif EXECUTE_DDL:\n    try:\n        setup_postgres.create_metadata_tables()\n        print(\"メタデータテーブルの作成を完了しました。\")\n    except Exception as e:  # noqa: BLE001\n        print(\"[エラー] DDL 実行に失敗:\", e)\nelse:\n    print(\"EXECUTE_DDL=False のため、DDL は実行していません。\")\n    print(\"DDL を実行したい場合は、このセル内のフラグを True に変更してください。\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## B. 特徴量生成パイプラインの確認\n\nこのセクションでは、ロト系のベーステーブルから特徴量テーブルを作るまでの流れを確認します。\n\n- B-1. ベーステーブル（例: `nf_loto_final`）の行数・カラム確認\n- B-2. `loto_etl` / `loto_etl_updated` による前処理スモークテスト\n- B-3. 特徴量テーブル（futr/hist/stat_*）のスキーマ確認\n\n※ 実際にどのテーブルから特徴量を生成するかは、あなたの DB のスキーマに合わせて変更してください。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### B-1. ベーステーブルの確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom nf_loto_platform.db import postgres_manager\n\nBASE_TABLE = \"nf_loto_final\"  # 必要に応じて変更\n\ntry:\n    with postgres_manager.get_connection() as conn:\n        q = f\"SELECT * FROM {BASE_TABLE} ORDER BY 1 LIMIT 100;\"\n        df_base = pd.read_sql(q, conn)\n    print(\"ベーステーブル:\", BASE_TABLE)\n    print(\"shape:\", df_base.shape)\n    display(df_base.head())\nexcept Exception as e:  # noqa: BLE001\n    print(\"[エラー] ベーステーブル読み込みに失敗:\", e)\n    df_base = None\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### B-2. ETL（loto_etl / loto_etl_updated）のスモークテスト"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.db import loto_etl, loto_etl_updated\n\n# ここでは「関数が呼べるか／最低限の戻り値が得られるか」を確認するイメージです。\n# 実際のシグネチャは実装に合わせて編集してください。\n\ntry:\n    print(\"loto_etl モジュール:\", loto_etl)\n    print(\"loto_etl_updated モジュール:\", loto_etl_updated)\n    # 例:\n    # etl_df = loto_etl.run_etl(limit=1000)\n    # print(\"etl_df shape:\", etl_df.shape)\nexcept Exception as e:  # noqa: BLE001\n    print(\"[エラー] ETL スモークテストに失敗:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### B-3. 特徴量テーブルのスキーマ確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 特徴量テーブル名は、あなたの環境の命名に合わせて変更してください。\nFEATURE_TABLE = \"nf_loto_features\"  # 仮の例\n\ntry:\n    from nf_loto_platform.db import postgres_manager\n    import pandas as pd\n\n    with postgres_manager.get_connection() as conn:\n        q = f\"SELECT * FROM {FEATURE_TABLE} ORDER BY 1 LIMIT 100;\"\n        df_feat = pd.read_sql(q, conn)\n    print(\"特徴量テーブル:\", FEATURE_TABLE)\n    print(\"shape:\", df_feat.shape)\n    print(\"カラム一覧:\", df_feat.columns.tolist())\n    display(df_feat.head())\nexcept Exception as e:  # noqa: BLE001\n    print(\"[注意] 特徴量テーブルの読み込みに失敗:\", e)\n    print(\"まだ特徴量生成が未実行、またはテーブル名が環境と合っていない可能性があります。\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## C. AutoML / モデル実行バックエンドの確認\n\nこのセクションでは、NeuralForecast AutoModels ベースの学習パイプラインが\n最低限動作するかどうかを確認します。\n\n- C-1. AutoModelBuilder のインポートと登録モデル一覧の確認\n- C-2. 極小データセットでのテスト実行（オプション）"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### C-1. AutoModelBuilder の確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.ml import automodel_builder\n\nprint(\"AutoModelBuilder モジュール:\", automodel_builder)\n\n# 登録済みモデル一覧を出すヘルパーがあれば利用し、無ければ dir() ベースで確認\ncandidates = [name for name in dir(automodel_builder) if \"Auto\" in name or \"create\" in name.lower()]\nprint(\"AutoModel 関連と思しきシンボル:\", candidates)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### C-2. 極小データセットでのテスト実行（オプション）"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom datetime import datetime, timedelta\n\nfrom nf_loto_platform.ml import model_runner\n\n# 極小サンプルデータセットを構築（NeuralForecast 用の基本形式）\ndates = [datetime(2020, 1, 1) + timedelta(days=i) for i in range(30)]\ndf_small = pd.DataFrame({\n    \"unique_id\": [\"series_1\"] * len(dates),\n    \"ds\": dates,\n    \"y\": [i % 10 for i in range(30)],\n})\n\nprint(\"サンプルデータ:\")\ndisplay(df_small.head())\n\n# 実際の model_runner の API に合わせて設定を組む必要があります。\n# ここでは疑似コード／テンプレ的な例として示します。\nRUN_TINY_EXPERIMENT = False  # True にすると実際に学習を試みる\n\nif RUN_TINY_EXPERIMENT:\n    try:\n        result = model_runner.run_single_model_experiment(\n            data=df_small,\n            model_name=\"AutoNHITS\",   # 実際にインストールされている Auto* 名に合わせて変更\n            horizon=7,\n            max_trials=1,\n            timeout_s=60,\n        )\n        print(\"実験結果:\", result)\n    except Exception as e:  # noqa: BLE001\n        print(\"[エラー] 極小実験の実行に失敗:\", e)\nelse:\n    print(\"RUN_TINY_EXPERIMENT=False のため、実際の学習は実行していません。\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## D. ログ・モニタリング・リソース利用の確認\n\nここでは、MLflow / W&B ロガー、および Prometheus / resource_monitor など\nモニタリング系のコンポーネントを軽く叩いてみます。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### D-1. MLflow / W&B ロガーのインポート確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.logging_ext import mlflow_logger, wandb_logger\n\nprint(\"mlflow_logger モジュール:\", mlflow_logger)\nprint(\"wandb_logger  モジュール:\", wandb_logger)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### D-2. リソース利用スナップショットの取得"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.monitoring import resource_monitor\n\ninfo = resource_monitor.collect_resource_usage()\nprint(\"resource_monitor.collect_resource_usage() ->\")\nfor k, v in info.items():\n    print(f\"  {k}: {v}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## E. WebUI / Streamlit 連携の確認\n\nStreamlit WebUI 自体はノートブック内では直接起動しませんが、\n少なくとも Python から import できるか／エントリポイントが見つかるかを確認します。"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\n\nstreamlit_app_path = PROJECT_ROOT / \"apps\" / \"webui_streamlit\" / \"streamlit_app.py\"\nrunner_path = PROJECT_ROOT / \"apps\" / \"webui_streamlit\" / \"nf_auto_runner_full.py\"\n\nprint(\"streamlit_app.py :\", streamlit_app_path, \"exists:\", streamlit_app_path.exists())\nprint(\"nf_auto_runner_full.py:\", runner_path, \"exists:\", runner_path.exists())\n\nprint(\"\"\"ローカルのシェルからは、例えば以下のように起動できます:\n  streamlit run apps/webui_streamlit/streamlit_app.py\n\"\"\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## F. 生成物・ログ・メタデータの確認\n\nこのセクションでは、モデル実行後に蓄積されることを想定しているテーブルや\nレポートファイルなどを確認します。\n\n- F-1. `nf_model_runs` / `nf_model_metrics` などのメタデータテーブル\n- F-2. HTML レポートの例\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### F-1. nf_* メタデータテーブル中身の確認"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd\nfrom nf_loto_platform.db_metadata import schema_definitions\nfrom nf_loto_platform.db import postgres_manager\n\ntables_to_inspect = [\n    schema_definitions.NF_MODEL_RUNS_TABLE,\n    schema_definitions.NF_MODEL_METRICS_TABLE,\n    schema_definitions.NF_DRIFT_METRICS_TABLE,\n]\n\nfor tbl in tables_to_inspect:\n    try:\n        with postgres_manager.get_connection() as conn:\n            q = f\"SELECT * FROM {tbl} ORDER BY 1 LIMIT 20;\"\n            df = pd.read_sql(q, conn)\n        print(f\"テーブル {tbl}: shape={df.shape}\")\n        display(df.head())\n    except Exception as e:  # noqa: BLE001\n        print(f\"[注意] テーブル {tbl} の読み込みに失敗:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### F-2. HTML レポートの表示例"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from nf_loto_platform.reports import html_reporter\n\n# シンプルなレポート文字列を作成\nhtml = html_reporter.render_simple_report(title=\"nf_loto_platform レポート例\", body=\"これはテスト用のレポートです。\")\n\n# 一時ファイルに書き出し\nfrom pathlib import Path\ntmp_report = PROJECT_ROOT / \"tmp_nf_loto_report_example.html\"\nhtml_reporter.write_report(tmp_report, html)\nprint(\"HTML レポートを書き出しました:\", tmp_report)\n\n# Jupyter 上で簡易表示（本格的なレンダリングはブラウザでファイルを開いて確認）\nfrom IPython.display import HTML\nHTML(html)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## G. pytest による回帰テストの一部実行\n\n最後に、ノートブックから pytest を呼び出して、\n一部または全テストを実行するサンプルを示します。\n\n> ⚠ 注意:  \n> フルテストは時間がかかる場合があります。まずは静的テストや core 層など、スコープを絞って実行することを推奨します。"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import subprocess\nimport sys\n\ndef run_pytest(args):\n    cmd = [sys.executable, \"-m\", \"pytest\"] + args\n    print(\"実行コマンド:\", \" \".join(cmd))\n    result = subprocess.run(cmd, cwd=PROJECT_ROOT, text=True)\n    return result.returncode\n\n# 例1: 静的チェックのみ\n# rc = run_pytest([\"tests/static\"])\n\n# 例2: core / db / ml のみ\n# rc = run_pytest([\"tests/core\", \"tests/db\", \"tests/ml\"])\n\nprint(\"必要なスコープを選んでコメントアウトを外し、実行してください。\")\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}